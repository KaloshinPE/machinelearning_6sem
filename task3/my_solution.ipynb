{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.tsv\")\n",
    "test = pd.read_csv(\"test.tsv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.tsv\")\n",
    "etalon = pd.read_csv(\"etalon.csv\")\n",
    "#train = train.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "dummy_features = ohe.fit_transform(all_data['item_id'].values.reshape(-1, 1))\n",
    "dummy_features = pd.DataFrame(dummy_features, columns=['good = ' + str(x) for x in range(dummy_features.shape[1])])\n",
    "all_data.index = dummy_features.index\n",
    "new_all_data = pd.concat([all_data, dummy_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_features = ohe.fit_transform(new_all_data['week'].values.reshape(-1, 1))\n",
    "dummy_features = pd.DataFrame(dummy_features, columns=['week = ' + str(x) for x in range(dummy_features.shape[1])])\n",
    "new_all_data.index = dummy_features.index\n",
    "new_all_data = pd.concat([new_all_data, dummy_features], axis=1).drop(['week'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_features = ohe.fit_transform(new_all_data['year'].values.reshape(-1, 1))\n",
    "dummy_features = pd.DataFrame(dummy_features, columns=['year = ' + str(x) for x in range(dummy_features.shape[1])])\n",
    "new_all_data.index = dummy_features.index\n",
    "new_all_data = pd.concat([new_all_data, dummy_features], axis=1).drop(['year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train = new_all_data.drop(['item_id', 'Num'], axis=1)[:len(train)]\n",
    "new_test = new_all_data.drop(['item_id', 'Num'], axis=1)[len(train):]\n",
    "new_test = new_test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = new_train.drop(['y'], axis=1).as_matrix(), new_train['y'].values\n",
    "X_test = new_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sum_regressor:\n",
    "    def __init__(self):\n",
    "        self.estimators = [RandomForestRegressor(n_estimators=17, min_samples_split=3), \n",
    "                          GradientBoostingRegressor(n_estimators=20, loss='lad'), \n",
    "                          ExtraTreesRegressor(n_estimators=20)]\n",
    "    def fit(self, X, y):\n",
    "        for est in self.estimators:\n",
    "            est.fit(X, np.log(y))\n",
    "            if est != self.estimators[-1]:\n",
    "                np.c_[X, est.predict(X)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        for est in self.estimators:\n",
    "            if est != self.estimators[-1]:\n",
    "                np.c_[X, est.predict(X)]\n",
    "        return np.exp(self.estimators[-1].predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est = RandomForestRegressor(n_estimators=17, min_samples_split=3)\n",
    "est.fit(X_train, y_train)\n",
    "preds = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission['y'] = preds\n",
    "sample_submission.set_index('Num', inplace=True)\n",
    "sample_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_estimator_onm(estimator):\n",
    "    def do_stuff(X, y):\n",
    "        tscv = TimeSeriesSplit(n_splits=10)\n",
    "        score = []\n",
    "        for train_index, test_index in tscv.split(X):\n",
    "            estimator.fit(X[train_index], y[train_index])\n",
    "            prediction = estimator.predict(X[test_index])\n",
    "            score.append(SMAPE(y[test_index], prediction))\n",
    "        print score\n",
    "        return np.mean(score)\n",
    "    return do_stuff(new_train.drop(['y'], axis=1).as_matrix(), new_train['y'].values)\n",
    "\n",
    "def test_on_etalon(estimator):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    return SMAPE(estimator.predict(X_test), etalon['y'].values)\n",
    "\n",
    "def SMAPE(target, prediction):\n",
    "    return 200*np.mean(np.abs(target-prediction)/(np.abs(target) + np.abs(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.8498838241\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f60_train = train['f60']\n",
    "f60_test = test['f60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['y'] = 0\n",
    "test = test.set_index(np.linspace(1, test.shape[0], test.shape[0]).astype(int))\n",
    "test['index1'] = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in test['index1']:\n",
    "    week = test.loc[(test['index1']==index)]['week'].values[0]\n",
    "    item = test.loc[(test['index1']==index)]['item_id'].values[0]\n",
    "    A = test.loc[(test['item_id'] == item) & (test['week']-test['shift']==week)]\n",
    "    if A.empty == False:\n",
    "        i = A.index[0]\n",
    "        test.set_value(index, 'y', A.loc[test['index1']==i]['f60'].values[0]*1.61)\n",
    "test = test.drop(['index1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preds_score(preds):\n",
    "    index = test['y'] != 0\n",
    "    print SMAPE(preds[index], etalon['y'].values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.4668510141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "preds_score(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
