{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.tsv\")\n",
    "test = pd.read_csv(\"test.tsv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.tsv\")\n",
    "train = train.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMAPE(target, prediction):\n",
    "    return 200*np.mean(np.abs(target-prediction)/(np.abs(target) + np.abs(prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate(estimator, train_data, log=False):\n",
    "    X = train_data.drop(['Num','y'], axis=1)\n",
    "    y = train_data['y']\n",
    "    def do_stuff(train_indexes, check_indexes, line=''):\n",
    "        estimator.fit(X[train_indexes], y[train_indexes])\n",
    "        pred = estimator.predict(X[check_indexes])\n",
    "        score = SMAPE(pred, y[check_indexes])\n",
    "        if log:\n",
    "            print line + str(score)\n",
    "        return score\n",
    "    scores = []\n",
    "    scores.append(do_stuff(X['year'] < 2014, X['year'] == 2014, \"trained on 2012, 2013, prediction for 2014: \"))\n",
    "    scores.append(do_stuff(X['year'] < 2014, X['year'] == 2015, \"trained on 2012, 2013, prediction for 2015: \"))\n",
    "    scores.append(do_stuff(X['year'] < 2015, X['year'] == 2015, \"trained on 2012 - 2014, prediction for 2015: \"))\n",
    "    scores.append(do_stuff(X['year'] == 2014, X['year'] == 2015, \"trained on 2014, prediction for 2015: \"))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "dummy_features = ohe.fit_transform(train['item_id'].values.reshape(-1, 1))\n",
    "dummy_features = pd.DataFrame(dummy_features, columns=['good = ' + str(x) for x in range(dummy_features.shape[1])])\n",
    "train.index = dummy_features.index\n",
    "new_train = pd.concat([train, dummy_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_alg(loss, n_estimators=50, max_depth=5, log=False):\n",
    "    print '\\n'\n",
    "    print 'loss: ' + loss \n",
    "    print 'estimators: ' + str(n_estimators)\n",
    "    print 'depth: ' + str(max_depth)\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    model = GradientBoostingRegressor(loss=loss, n_estimators=n_estimators, criterion='mae', max_depth=5, random_state=43)\n",
    "    if log:\n",
    "        print 'raw: '\n",
    "    raw_scores = validate(model, train, log)\n",
    "    if log:\n",
    "        print 'modified: '\n",
    "    modified_scores = validate(model, new_train.drop(['item_id'], axis=1), log)\n",
    "    return raw_scores, modified_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебор числа деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 1\n",
      "depth: True\n",
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 5\n",
      "depth: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e7085bbd8d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mraw_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodified_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6ba35f3a9ac9>\u001b[0m in \u001b[0;36mtest_alg\u001b[0;34m(loss, n_estimators, max_depth, log)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'modified: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodified_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mraw_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e9fc82299ea5>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(estimator, train_data, log)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trained on 2012, 2013, prediction for 2014: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trained on 2012, 2013, prediction for 2015: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trained on 2012 - 2014, prediction for 2015: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trained on 2014, prediction for 2015: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e9fc82299ea5>\u001b[0m in \u001b[0;36mdo_stuff\u001b[0;34m(train_indexes, check_indexes, line)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raw_scores = []\n",
    "modified_scores = []\n",
    "n_values = [1, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150]\n",
    "for n in n_values:\n",
    "    r1, r2 = test_alg('lad', n, True)\n",
    "    raw_scores.append(r1)\n",
    "    modified_scores.append(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_scores_arr = np.array(raw_scores).transpose()\n",
    "modified_scores_arr = np.array(modified_scores).transpose()\n",
    "names = [\"2012, 2013 -> 2014\", \"2012, 2013 -> 2015: \", \n",
    "        \"2012 - 2014 -> 2015: \", \"2014 -> 2015: \"]\n",
    "my_colors = ['r', 'g', 'b', 'c']\n",
    "\n",
    "for i in range(4):    \n",
    "    plt.plot(n_values, raw_scores_arr[i], label=names[i] + ' raw', color=my_colors[i], alpha = 0.5)\n",
    "    plt.plot(n_values, modified_scores_arr[i], label=names[i] + ' modified', color=my_colors[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 20\n",
      "depth: 5\n",
      "raw: \n",
      "trained on 2012, 2013, prediction for 2014: 57.4441904017\n",
      "trained on 2012, 2013, prediction for 2015: 85.7790723228\n",
      "trained on 2012 - 2014, prediction for 2015: 93.3162882665\n",
      "trained on 2014, prediction for 2015: 99.3746693963\n",
      "modified: \n",
      "trained on 2012, 2013, prediction for 2014: 59.2980544846\n",
      "trained on 2012, 2013, prediction for 2015: 87.1512544171\n",
      "trained on 2012 - 2014, prediction for 2015: 91.1851139179\n",
      "trained on 2014, prediction for 2015: 93.3999819141\n",
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 30\n",
      "depth: 5\n",
      "raw: \n",
      "trained on 2012, 2013, prediction for 2014: 45.8928249323\n",
      "trained on 2012, 2013, prediction for 2015: 79.011477092\n",
      "trained on 2012 - 2014, prediction for 2015: 90.5739393927\n",
      "trained on 2014, prediction for 2015: 98.4362314089\n",
      "modified: \n",
      "trained on 2012, 2013, prediction for 2014: 46.4223407821\n",
      "trained on 2012, 2013, prediction for 2015: 81.0516399828\n",
      "trained on 2012 - 2014, prediction for 2015: 86.386264103\n",
      "trained on 2014, prediction for 2015: 92.9844847719\n",
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 40\n",
      "depth: 5\n",
      "raw: \n",
      "trained on 2012, 2013, prediction for 2014: 38.367368262\n",
      "trained on 2012, 2013, prediction for 2015: 75.697337244\n",
      "trained on 2012 - 2014, prediction for 2015: 86.0361049126\n",
      "trained on 2014, prediction for 2015: 95.2260775226\n",
      "modified: \n",
      "trained on 2012, 2013, prediction for 2014: 38.1460094256\n",
      "trained on 2012, 2013, prediction for 2015: 75.5094198238\n",
      "trained on 2012 - 2014, prediction for 2015: 80.4911852381\n",
      "trained on 2014, prediction for 2015: 88.4104006743\n",
      "\n",
      "\n",
      "loss: lad\n",
      "estimators: 50\n",
      "depth: 5\n",
      "raw: \n",
      "trained on 2012, 2013, prediction for 2014: 34.5606933698\n",
      "trained on 2012, 2013, prediction for 2015: 72.720935376\n",
      "trained on 2012 - 2014, prediction for 2015: 81.7998781417\n",
      "trained on 2014, prediction for 2015: 91.0766110997\n",
      "modified: \n",
      "trained on 2012, 2013, prediction for 2014: 34.0986994737\n",
      "trained on 2012, 2013, prediction for 2015: 71.0639598979\n",
      "trained on 2012 - 2014, prediction for 2015: 79.3225838739\n"
     ]
    }
   ],
   "source": [
    "raw_scores = []\n",
    "modified_scores = []\n",
    "n_values = [20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150]\n",
    "for n in n_values:\n",
    "    r1, r2 = test_alg(loss='lad', n_estimators=n, log=True)\n",
    "    raw_scores.append(r1)\n",
    "    modified_scores.append(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (15,) and (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-47d58a2140b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_scores_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_colors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodified_scores_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' modified'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_colors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3316\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3318\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3319\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3320\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pavel/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (15,) and (7,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAJDCAYAAABOhiZdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACGEXIAAADD/A/2GrlhiBJhuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02fc792990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_scores_arr = np.array(raw_scores).transpose()\n",
    "modified_scores_arr = np.array(modified_scores).transpose()\n",
    "names = [\"2012, 2013 -> 2014\", \"2012, 2013 -> 2015: \", \n",
    "        \"2012 - 2014 -> 2015: \", \"2014 -> 2015: \"]\n",
    "my_colors = ['r', 'g', 'b', 'c']\n",
    "\n",
    "for i in range(4):    \n",
    "    plt.plot(n_values, raw_scores_arr[i], label=names[i] + ' raw', color=my_colors[i], alpha = 0.5)\n",
    "    plt.plot(n_values, modified_scores_arr[i], label=names[i] + ' modified', color=my_colors[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глубина не играет роли. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
